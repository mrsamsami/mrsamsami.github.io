<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1, viewport-fit=cover">
  <title>Mo Samsami</title>
  <meta name="description" content="Homepage of Mohammad Reza Samsami, a research engineer at Google DeepMind.">
  <link rel="icon" href="assets/images/ChatGPT Image Aug 8, 2025, 04_05_40 PM.png" />
  <!-- Custom minimal yet sharp stylesheet -->
  <link rel="stylesheet" href="assets/css/style.css">
  <!-- Font Awesome icons stylesheet imported from the template to enable icons -->
  <link rel="stylesheet" href="assets/css/fontawesome-all.min.css">
</head>
<body>
  <!-- Navigation -->
  <nav>
    <div class="nav-container">
      <!-- Centered navigation links without brand -->
      <ul>
        <li><a href="#home" class="active">Intro</a></li>
        <li><a href="#about">Perspective</a></li>
        <li><a href="#publications">Work</a></li>
        <!-- <li><a href="#blog">Blog</a></li> -->
        <!-- Theme toggle button: placed alongside the navigation links.  It uses
             a simple circle with rays to indicate light mode.  When clicked it
             toggles dark mode on the page and switches its appearance to a
             solid white circle.  See style.css for styling details. -->
        <li>
          <button id="theme-toggle" class="theme-toggle light" aria-label="Toggle dark mode">
            <span class="icon"></span>
          </button>
        </li>
      </ul>
    </div>
  </nav>

  <!-- Hero Section -->
  <section class="hero" id="home">
    <div class="container">
      <div class="photo">
        <img src="assets/images/profile.jpg" alt="Portrait of Mo Samsami">
      </div>
      <div class="intro">
        <h1>Mohammad Reza Samsami</h1>
        <h2>Research Engineer @ Google DeepMind</h2>
        <p>
          I’m Mo, a Research Engineer at <a href="https://deepmind.google/">Google DeepMind</a> in RL Engineering Team. I earned my master’s at <a href="https://mila.quebec/en">Mila</a> and have interned at <a href="https://research.google/">Google Research</a>, <a href="https://www.servicenow.com/research/">ServiceNow Research</a>, and <a href="https://www.epfl.ch/en/">EPFL</a>. I also co-founded <a href="https://www.zette.ai/">Zette AI</a>. Before that, I studied at <a href="https://en.sharif.ir/sharif-university-of-technology">Sharif University of Technology</a>, where as an undergrad I co-founded <a href="https://www.linkedin.com/company/sharif-cognitive-sciences-community-shenasa/about/">Shenasa</a>, a multidisciplinary student community on cognitive science.
</p><p>
My research goal is building generally intelligent machines that can plan under uncertainty in complex environments. I’m particulary interested in devloping machines that learn from experience, form rich internal models of the world, simulate possible futures, and choose actions with foresight.
My current focus is on <a href="https://deepmind.google/discover/blog/genie-3-a-new-frontier-for-world-models/">Genie</a>.</p>
        <!-- Buttons will be placed in a separate call-to-action section below the card -->
      </div>
    </div>
    <!-- Call to action area: unified contact icons for CV, email and socials -->
    <div class="cta">
      <div class="contact-icons">
        <!-- Link to CV -->
        <!-- <a href="documents/CV.pdf" target="_blank" aria-label="My CV" title="My CV"><i class="fas fa-file-alt"></i></a> -->
        <!-- Email link -->
        <a href="mailto:mohammadrezasamsami76@gmail.com" aria-label="Email" title="Email"><i class="fas fa-envelope"></i></a>
        <!-- Twitter -->
        <a href="https://twitter.com/M_R_Samsami" target="_blank" aria-label="Twitter" title="Twitter"><i class="fab fa-twitter"></i></a>
        <!-- Google Scholar -->
        <a href="https://scholar.google.com/citations?user=0_tOLp8AAAAJ&amp;hl=en" target="_blank" aria-label="Google Scholar" title="Google Scholar"><i class="fab fa-google"></i></a>
        <!-- LinkedIn -->
        <a href="https://linkedin.com/in/mohammadrezasamsami/" target="_blank" aria-label="LinkedIn" title="LinkedIn"><i class="fab fa-linkedin-in"></i></a>
        <!-- GitHub -->
        <a href="https://github.com/mrsamsami" target="_blank" aria-label="GitHub" title="GitHub"><i class="fab fa-github"></i></a>
      </div>
    </div>
  </section>

  <!-- About Section -->
  <section id="about">
    <h2 class="section-title">Research Perspective</h2>
    <ol class="perspective-list">
      <li>Human and animal intelligence is based on a huge amount of background knowledge about how the world operates, which has been developed through observation and interaction. <a href="https://openreview.net/pdf?id=BZ5a1r-kVsf" type="_blank">Internal models of the world</a> guide judgments about what is likely, plausible, or impossible.</li>
      <li>Inspired by that, my work centers on <a href="https://www.nvidia.com/en-us/glossary/world-models/">world models</a>: neural networks that transform raw sensory streams into semantic, spatio‑temporal representations. With these, machines can predict outcomes, reason about choices, and plan over long horizons.</li>
      <li>Reinforcement learning provides a paradigm that can use world models to come up with an intelligent behavior. Despite progress in AI, general‑purpose decision‑making in open‑ended, dynamic settings is still a challenging problem.</li>
      <li>One obstacle is complexity: real world is visually, temporally, and interactively rich, which makes modeling it a central challenge. I advocate integrating perception across modalities (like video, language, and action) to develop agents that operate reliably in realistic settings, especially where physical interaction matters.</li>
      <li>In this spirit, I work on <a href="https://deepmind.google/discover/blog/genie-3-a-new-frontier-for-world-models/" data-tip="Genie is a generative world model, capable of producing rich interactive environments.">Genie</a> to help make scalable world models practical and to bring these ideas closer to meaningful real‑world impact.</li>
    </ol>
  </section>

  <!-- Publications Section -->
  <section id="publications">
    <h2 class="section-title">Some Publications</h2>
    <div class="publication-list">
      <a href="https://recall2imagine.github.io" target="_blank" class="publication-card">
        <h3>Mastering Memory Tasks with World Models</h3>
        <div class="authors"><strong>Mohammad Reza Samsami*</strong>, Artem Zholus*, Janarthanan Rajendran, Sarath Chandar</div>
        <div class="pub-year">2024</div>
        <div class="label">oral (top‑1.2%) at ICLR</div>
        <p class="pub-description">My first paper on world models, asking a simple question: if an agent could recall better, could it make better decisions?
          We focused on the memory bottleneck in world models and introduced <span style="font-family: 'Cinzel'">R2I</span>, an RL agent with improved memory. 
          <span style="font-family: 'Cinzel'">R2I</span> not only achieves superhuman performance on memory-heavy tasks but also remains competitive across diverse domains.</p>
      </a>
      <a href="https://2big2fool.github.io" target="_blank" class="publication-card">
        <h3>Too Big to Fool: Resisting Deception in Language Models</h3>
        <div class="authors"><strong>Mohammad Reza Samsami</strong>, Mats Leon Richter, Juan A. Rodriguez, Megh Thakkar, Sarath Chandar, Maxime Gasse</div>
        <div class="pub-year">2024</div>
        <!-- <div class="label">Preprint</div> -->
        <p class="pub-description">I also explored world models in the context of LLMs, asking: do larger models, with stronger overall performance, develop richer internal representations of the world? Our experiments suggest they do, showing that larger models are notably more resilient to misleading in-context cues, thanks to their ability to integrate prompt information with a stronger underlying world model.</p>
      </a>
      <a href="https://t.co/8cU4sI4VUS" target="_blank" class="publication-card">
        <h3>Interpretability in Action: Exploratory Analysis of VPT, a Minecraft Agent</h3>
        <div class="authors">Karolis Jucys*, George Adamopoulos*, Mehrab Hamidi, Stephanie Milani, <strong>Mohammad Reza Samsami</strong>, Artem Zholus, Sonia Joseph, Blake Richards, Irina Rish, Özgür Şimşek</div>
        <div class="pub-year">2024</div>
        <!-- <div class="label">Mechanistic Interpretability Workshop, ICML 2024</div> -->
        <p class="pub-description">Not a world model paper per se, but closely related in spirit: examining how a foundation-model agent perceives the world and acts based on its perception. Through mechanistic interpretability, we discovered patterns in how the VPT agent links recent observations to decisions, as well as scenarios where its perception led to misaligned behavior, like killing villagers.</p>
      </a>

      <!-- Rendering‑Aware Reinforcement Learning for Vector Graphics Generation -->
      <a href="https://arxiv.org/abs/2505.20793" class="publication-card" target="_blank">
        <h3>Rendering‑Aware Reinforcement Learning for Vector Graphics Generation</h3>
        <div class="authors">Juan A Rodriguez, Haotian Zhang, Abhay Puri, Aarash Feizi, Rishav Pramanik, Pascal Wichmann, Arnab Mondal, <strong>Mohammad Reza Samsami</strong>, Rabiul Awal, Perouz Taslakian, Spandana Gella, Sai Rajeswar, David Vazquez, Christopher Pal, Marco Pedersoli</div>
        <!-- description -->
        <div class="pub-year">2025</div>
        <p class="pub-description">In the same spirit of agents learning through interaction with a world or its proxy, this work frames SVG generation as an RL loop: the model writes code, renders it, and optimizes for visual fidelity, learning how its actions shape outcomes without requiring differentiable rendering.</p>
      </a>
      <a href="https://mrsamsami.github.io/causal-imitation" target="_blank" class="publication-card">
        <h3>Causal Imitative Model for Autonomous Driving</h3>
        <div class="authors"><strong>Mohammad Reza Samsami</strong>, Mohammadhossein Bahari, Saber Salehkaleybar, Alexandre Alahi</div>
        <div class="pub-year">2021</div>
        <!-- <div class="label">Preprint</div> -->
        <p class="pub-description">From an earlier chapter of my work, when I was particularly interested in applying causality to enhance decision-making systems. We explored how explicitly modeling causal structure can lead to more reliable policies. In the context of autonomous driving, this approach helped train policies that avoided common pitfalls such as inertia and collisions.</p>
      </a>
    </div>
  </section>

  <!-- Blog Section -->
  <!-- <section id="blog">
    <h2 class="section-title">Blog</h2>
    <div class="publication-list">
      <a href="blog/machines-and-cinema.html" class="publication-card">
        <h3>The Age of Machines and Cinema’s New Role</h3>
        <div class="authors"><strong>Mohammad Reza Samsami</strong></div>
        <div class="pub-year">2025</div>
        <p class="pub-description">We’re entering an era when designed systems change the world faster than we can keep up. I argue for intentional progress: keep building, but match speed with reflection and intention. In that light, cinema can be a compass. As a shared moment of focus and presence, it can help guide the new interactive media we’re creating and remind us what’s worth building.</p>
      </a>
    </div>
  </section> -->


  <!-- Footer -->
  <footer>
    <div class="footer-content">Last updated on September 20th 2025 © Vibe Coded by Mo Samsami.</div>
  </footer>

  <!-- Active nav highlighting script -->
  <script>
    const navLinks = document.querySelectorAll('nav a');
    window.addEventListener('scroll', () => {
      const fromTop = window.scrollY + 130;
      navLinks.forEach(link => {
        const section = document.querySelector(link.getAttribute('href'));
        if (!section) return;
        if (section.offsetTop <= fromTop && section.offsetTop + section.offsetHeight > fromTop) {
          link.classList.add('active');
        } else {
          link.classList.remove('active');
        }
      });
    });

    // Theme toggling logic: clicking the button toggles the `dark-mode` class on
    // the document body and switches the icon between a sun (with rays)
    // and a solid circle.  A "light" class on the button indicates
    // light mode; a "dark" class indicates dark mode.  Using classes
    // instead of inline styles keeps the markup clean and makes it easy
    // to extend the appearance via CSS.
    const themeToggle = document.getElementById('theme-toggle');
    themeToggle.addEventListener('click', () => {
      const isDark = document.body.classList.toggle('dark-mode');
      themeToggle.classList.toggle('dark', isDark);
      themeToggle.classList.toggle('light', !isDark);
    });

    // Reveal publication cards on scroll.  Cards start slightly translated
    // downward and fully transparent (see CSS).  When they enter the
    // viewport, we add a `revealed` class to trigger a fade‑up effect.  We
    // unobserve each card after revealing to avoid repeated toggling.
    const pubCards = document.querySelectorAll('.publication-card');
    const cardObserver = new IntersectionObserver((entries, observer) => {
      entries.forEach(entry => {
        if (entry.isIntersecting) {
          entry.target.classList.add('revealed');
          observer.unobserve(entry.target);
        }
      });
    }, { threshold: 0.15 });
    pubCards.forEach(card => cardObserver.observe(card));

    /* -----------------------------------------------------------------------
       Cross‑page fade logic

       To preserve the elegant feel of the site when navigating between
       pages, we implement a simple fade‑in/fade‑out transition.  On page
       load the body gradually appears from opacity 0 to 1.  When the
       user clicks any in‑page link (that doesn’t open in a new tab), we
       briefly fade out the current page before navigating away.  This
       script is reused on blog pages to maintain a consistent
       experience. */
    document.addEventListener('DOMContentLoaded', () => {
      // Begin fade in after DOM is ready
      document.body.classList.add('fade-in');
    });
    document.querySelectorAll('a').forEach(anchor => {
      anchor.addEventListener('click', (e) => {
        const hrefAttr = anchor.getAttribute('href');
        const target = anchor.getAttribute('target');
        // Only intercept same‑window navigations and real links.  Use
        // anchor.href to obtain an absolute, encoded URL so that spaces
        // and special characters (like parentheses) are handled
        // correctly.
        if (hrefAttr && !hrefAttr.startsWith('#') && target !== '_blank' && !anchor.dataset.noTransition) {
          e.preventDefault();
          document.body.classList.remove('fade-in');
          document.body.classList.add('fade-out');
          const destination = anchor.href;
          setTimeout(() => {
            window.location.assign(destination);
          }, 200);
        }
      });
    });
  </script>
</body>
</html>